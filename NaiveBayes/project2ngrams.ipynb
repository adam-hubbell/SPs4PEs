{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import pickle\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows = []\n",
    "with open('forumTest.data', \"r\") as fp:\n",
    "    rows = [line.split(\" \",1) for line in fp.readlines()]\n",
    "test = pd.DataFrame(rows,columns=[\"subject\",\"content\"])\n",
    "rows = []\n",
    "with open('forumTraining.data', \"r\") as fp:\n",
    "    rows = [line.split(\" \",1) for line in fp.readlines()]\n",
    "training = pd.DataFrame(rows,columns=[\"subject\",\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'vocab2.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b3e16cf16475>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vocab2.pickle'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mvocab2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vocab3.pickle'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvocab3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trgroup.pickle'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'vocab2.pickle'"
     ]
    }
   ],
   "source": [
    "with open('vocab2.pickle','rb') as file:\n",
    "    vocab2 = pickle.load(file)\n",
    "with open('vocab3.pickle','rb') as file:\n",
    "    vocab3 = pickle.load(file)\n",
    "with open('trgroup.pickle','rb') as file:\n",
    "    trgroup = pickle.load(file)\n",
    "with open('probs.pickle','rb') as file:\n",
    "    probs = pickle.load(file)\n",
    "with open('text2.pickle','rb') as file:\n",
    "    text2 = pickle.load(file)\n",
    "with open('wtprob2.pickle','rb') as file:\n",
    "    wtprob2 = pickle.load(file)\n",
    "with open('text3.pickle','rb') as file:\n",
    "    text3 = pickle.load(file)\n",
    "with open('wtprob3.pickle','rb') as file:\n",
    "    wtprob3 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#collect the vocab\n",
    "#run the pickle\n",
    "vocab2 = {}\n",
    "vocab3 = {}\n",
    "for k,row in training.iterrows():\n",
    "    words = row.content.split(\" \")\n",
    "    for i in range(len(words)-1):\n",
    "        g2 = \"%s %s\"%(words[i],words[i+1])\n",
    "        vocab2[g2] = 0\n",
    "        try: #handles the edge case of the final index, which produces a 2-gram but is out of bounds for a 3-gram\n",
    "            g3 = \"%s %s %s\"%(words[i],words[i+1],words[i+2])        \n",
    "            vocab3[g3] = 0\n",
    "        except IndexError:\n",
    "            pass \n",
    "vocab2 = list(vocab2.keys())\n",
    "vocab3 = list(vocab3.keys())\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = wtprob2\n",
    "with open('vocab2.pickle','wb') as file:\n",
    "    pickle.dump(vocab2,file)\n",
    "with open('vocab3.pickle','wb') as file:\n",
    "    pickle.dump(vocab3,file)\n",
    "with open('trgroup.pickle','wb') as file:\n",
    "    pickle.dump(trgroup,file)\n",
    "with open('probs.pickle','wb') as file:\n",
    "    pickle.dump(probs,file)\n",
    "with open('text2.pickle','wb') as file:\n",
    "    pickle.dump(text2,file)\n",
    "with open('wtprob2.pickle','wb') as file:\n",
    "    pickle.dump(wtprob2,file)\n",
    "with open('text3.pickle','wb') as file:\n",
    "    pickle.dump(text3,file)\n",
    "with open('wtprob3.pickle','wb') as file:\n",
    "    pickle.dump(wtprob3,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atheism 2019-02-17 19:00:34.477829\n",
      "atheism starting to split 2019-02-17 19:00:34.478107\n",
      "atheism starting 2grams 2019-02-17 19:00:34.942063\n",
      "atheism starting 3grams2019-02-17 19:00:36.356791\n",
      "autos 2019-02-17 19:00:39.185606\n",
      "autos starting to split 2019-02-17 19:00:39.185895\n",
      "autos starting 2grams 2019-02-17 19:00:39.536021\n",
      "autos starting 3grams2019-02-17 19:00:40.750362\n",
      "baseball 2019-02-17 19:00:43.745538\n",
      "baseball starting to split 2019-02-17 19:00:43.745816\n",
      "baseball starting 2grams 2019-02-17 19:00:44.143786\n",
      "baseball starting 3grams2019-02-17 19:00:45.472160\n",
      "christianity 2019-02-17 19:00:48.267390\n",
      "christianity starting to split 2019-02-17 19:00:48.267655\n",
      "christianity starting 2grams 2019-02-17 19:00:49.012381\n",
      "christianity starting 3grams2019-02-17 19:00:50.287602\n",
      "cryptology 2019-02-17 19:00:53.205385\n",
      "cryptology starting to split 2019-02-17 19:00:53.205647\n",
      "cryptology starting 2grams 2019-02-17 19:00:53.854385\n",
      "cryptology starting 3grams2019-02-17 19:00:55.075016\n",
      "electronics 2019-02-17 19:00:57.790011\n",
      "electronics starting to split 2019-02-17 19:00:57.790273\n",
      "electronics starting 2grams 2019-02-17 19:00:58.140885\n",
      "electronics starting 3grams2019-02-17 19:00:59.376281\n",
      "forsale 2019-02-17 19:01:01.983993\n",
      "forsale starting to split 2019-02-17 19:01:01.984250\n",
      "forsale starting 2grams 2019-02-17 19:01:02.198337\n",
      "forsale starting 3grams2019-02-17 19:01:03.431749\n",
      "graphics 2019-02-17 19:01:06.111428\n",
      "graphics starting to split 2019-02-17 19:01:06.111691\n",
      "graphics starting 2grams 2019-02-17 19:01:06.470937\n",
      "graphics starting 3grams2019-02-17 19:01:07.687762\n",
      "guns 2019-02-17 19:01:10.271520\n",
      "guns starting to split 2019-02-17 19:01:10.271787\n",
      "guns starting 2grams 2019-02-17 19:01:10.794063\n",
      "guns starting 3grams2019-02-17 19:01:12.037125\n",
      "hockey 2019-02-17 19:01:14.758373\n",
      "hockey starting to split 2019-02-17 19:01:14.758654\n",
      "hockey starting 2grams 2019-02-17 19:01:15.243435\n",
      "hockey starting 3grams2019-02-17 19:01:16.457259\n",
      "mac 2019-02-17 19:01:19.119239\n",
      "mac starting to split 2019-02-17 19:01:19.119503\n",
      "mac starting 2grams 2019-02-17 19:01:19.408419\n",
      "mac starting 3grams2019-02-17 19:01:20.656843\n",
      "medicine 2019-02-17 19:01:23.184931\n",
      "medicine starting to split 2019-02-17 19:01:23.185198\n",
      "medicine starting 2grams 2019-02-17 19:01:23.669997\n",
      "medicine starting 3grams2019-02-17 19:01:25.233978\n",
      "mideastpolitics 2019-02-17 19:01:28.005446\n",
      "mideastpolitics starting to split 2019-02-17 19:01:28.005726\n",
      "mideastpolitics starting 2grams 2019-02-17 19:01:28.749015\n",
      "mideastpolitics starting 3grams2019-02-17 19:01:30.287241\n",
      "motorcycles 2019-02-17 19:01:33.258412\n",
      "motorcycles starting to split 2019-02-17 19:01:33.258678\n",
      "motorcycles starting 2grams 2019-02-17 19:01:33.680808\n",
      "motorcycles starting 3grams2019-02-17 19:01:35.041867\n",
      "mswindows 2019-02-17 19:01:37.568417\n",
      "mswindows starting to split 2019-02-17 19:01:37.568676\n",
      "mswindows starting 2grams 2019-02-17 19:01:37.822493\n",
      "mswindows starting 3grams2019-02-17 19:01:39.075605\n",
      "pc 2019-02-17 19:01:41.954011\n",
      "pc starting to split 2019-02-17 19:01:41.954284\n",
      "pc starting 2grams 2019-02-17 19:01:42.297452\n",
      "pc starting 3grams2019-02-17 19:01:43.544075\n",
      "politics 2019-02-17 19:01:46.147832\n",
      "politics starting to split 2019-02-17 19:01:46.148096\n",
      "politics starting 2grams 2019-02-17 19:01:46.745235\n",
      "politics starting 3grams2019-02-17 19:01:48.093990\n",
      "religion 2019-02-17 19:01:50.682198\n",
      "religion starting to split 2019-02-17 19:01:50.682458\n",
      "religion starting 2grams 2019-02-17 19:01:51.072997\n",
      "religion starting 3grams2019-02-17 19:01:52.524692\n",
      "space 2019-02-17 19:01:55.415843\n",
      "space starting to split 2019-02-17 19:01:55.416113\n",
      "space starting 2grams 2019-02-17 19:01:55.919164\n",
      "space starting 3grams2019-02-17 19:01:57.218189\n",
      "xwindows 2019-02-17 19:01:59.768439\n",
      "xwindows starting to split 2019-02-17 19:01:59.768701\n",
      "xwindows starting 2grams 2019-02-17 19:02:00.266168\n",
      "xwindows starting 3grams2019-02-17 19:02:01.510864\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "#run the pickle\n",
    "#calculate probability estimates \n",
    "trgroup = training.groupby('subject')\n",
    "docs ={}\n",
    "probs = {g:0 for g in trgroup.groups.keys()}\n",
    "text2 = {g:{} for g in trgroup.groups.keys()}\n",
    "text3 = {g:{} for g in trgroup.groups.keys()}\n",
    "wtprob2 = {g:{} for g in trgroup.groups.keys()} \n",
    "wtprob3 = {g:{} for g in trgroup.groups.keys()} \n",
    "for g, cont in trgroup:\n",
    "    print(g+\" \"+str(datetime.datetime.now()))\n",
    "    docs[g] = cont.content.tolist()\n",
    "    probs[g] = len(cont)/len(training)\n",
    "    print(g+\" starting to split \"+str(datetime.datetime.now()))\n",
    "    for cnt in docs[g]:\n",
    "        cnttxt = cnt.split(\" \")\n",
    "        for i in range(len(cnttxt)-1):\n",
    "            try:\n",
    "                text2[g][\"%s %s\"%(cnttxt[i],cnttxt[i+1])] += 1\n",
    "            except KeyError:\n",
    "                text2[g][\"%s %s\"%(cnttxt[i],cnttxt[i+1])] = 1\n",
    "            try:\n",
    "                try:\n",
    "                    text3[g][\"%s %s %s\"%(cnttxt[i],cnttxt[i+1],cnttxt[i+2])] += 1\n",
    "                except KeyError:\n",
    "                    text3[g][\"%s %s %s\"%(cnttxt[i],cnttxt[i+1],cnttxt[i+2])] = 1 \n",
    "            except IndexError:\n",
    "                pass\n",
    "    n2 = len(text2[g])\n",
    "    n3 = len(text3[g])\n",
    "    print(g+\" starting 2grams \"+str(datetime.datetime.now()))\n",
    "    for gram in vocab2:\n",
    "        nk = 0\n",
    "        try:\n",
    "            nk = text2[g][gram]\n",
    "        except KeyError:\n",
    "            pass\n",
    "        wtprob2[g][gram] = math.log((nk + 1)/(n2+len(vocab2)))\n",
    "    print(g+\" starting 3grams\"+str(datetime.datetime.now()))\n",
    "    for gram in vocab3:\n",
    "        nk = 0\n",
    "        try:\n",
    "            nk = text3[g][gram]\n",
    "        except KeyError:\n",
    "                pass\n",
    "        wtprob3[g][gram] = math.log((nk + 1)/(n3+len(vocab3)))\n",
    "print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 win2:540 win3:553 2019-02-17 19:02:19.193523\n",
      "2000 win2:1142 win3:1086 2019-02-17 19:02:29.113371\n",
      "3000 win2:1843 win3:1786 2019-02-17 19:02:39.195139\n",
      "4000 win2:2565 win3:2526 2019-02-17 19:02:50.114785\n",
      "5000 win2:3291 win3:3253 2019-02-17 19:03:01.620427\n",
      "6000 win2:3958 win3:3931 2019-02-17 19:03:16.662927\n",
      "7000 win2:4868 win3:4782 2019-02-17 19:03:36.408110\n",
      "2grams: 0.680659% correct ~ 3grams: 0.679065% correct \n"
     ]
    }
   ],
   "source": [
    "win2 = 0.0\n",
    "lose2 = 0.0\n",
    "win3 = 0.0\n",
    "lose3 = 0.0\n",
    "for idx,tent in test.iterrows():\n",
    "    maxnb2 = -9999999999\n",
    "    maxg2 = \"\"\n",
    "    maxnb3 = -9999999999\n",
    "    maxg3 = \"\"\n",
    "    if idx > 0 and idx%1000 == 0:\n",
    "        print(\"%d win2:%d win3:%d %s\"%(idx,win2,win3,str(datetime.datetime.now())))\n",
    "    for g in trgroup.groups.keys():\n",
    "        tot2 = math.log(probs[g])\n",
    "        tot3 = math.log(probs[g])\n",
    "        words = tent.content.split(\" \")\n",
    "        words2 = []\n",
    "        words3 = []\n",
    "        for i in range(len(words)-1):\n",
    "            words2.append(\"%s %s\"%(words[i],words[i+1]))\n",
    "            try:\n",
    "                words3.append(\"%s %s %s\"%(words[i],words[i+1],words[i+2]))\n",
    "            except IndexError:\n",
    "                pass\n",
    "        for word in words2:\n",
    "            try:\n",
    "                tot2 += wtprob2[g][word]     \n",
    "            except KeyError:\n",
    "                pass\n",
    "        for word in words3:\n",
    "            try:\n",
    "                tot3 += wtprob3[g][word]     \n",
    "            except KeyError:\n",
    "                pass\n",
    "        if tot2 > maxnb2:\n",
    "            maxnb2 = tot2\n",
    "            maxg2 = g\n",
    "            \n",
    "        if tot3 > maxnb3:\n",
    "            maxnb3 = tot3\n",
    "            maxg3 = g\n",
    "    if maxg2 == tent.subject:\n",
    "        win2 += 1.0\n",
    "    else:\n",
    "        lose2 += 1.0\n",
    "    if maxg3 == tent.subject:\n",
    "        win3 += 1.0\n",
    "    else:\n",
    "        lose3 += 1.0\n",
    "print(\"2grams: %f%% correct ~ 3grams: %f%% correct \"%(win2/len(test), win3/len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#30 subject:mideastpolitics word:policy research score:16.363078\n",
      "#29 subject:space word:space station score:16.641208\n",
      "#28 subject:hockey word:the flyers score:16.660889\n",
      "#27 subject:space word:the moon score:16.726376\n",
      "#26 subject:mideastpolitics word:the israeli score:16.838574\n",
      "#25 subject:baseball word:the braves score:16.845635\n",
      "#24 subject:xwindows word:output oname score:16.863796\n",
      "#23 subject:medicine word:gordon banks score:16.903320\n",
      "#22 subject:hockey word:the leafs score:16.929715\n",
      "#21 subject:mideastpolitics word:serdar argic score:16.932812\n",
      "#20 subject:mideastpolitics word:soviet armenia score:17.047479\n",
      "#19 subject:politics word:ms myers score:17.056165\n",
      "#18 subject:hockey word:the puck score:17.135718\n",
      "#17 subject:mideastpolitics word:turks and score:17.281672\n",
      "#16 subject:mideastpolitics word:the turks score:17.377391\n",
      "#15 subject:cryptology word:public key score:17.448504\n",
      "#14 subject:hockey word:power play score:17.460506\n",
      "#13 subject:christianity word:apr athos score:17.512183\n",
      "#12 subject:motorcycles word:the bike score:17.619350\n",
      "#11 subject:cryptology word:key escrow score:17.786153\n",
      "#10 subject:cryptology word:the nsa score:17.797415\n",
      "#9 subject:xwindows word:window manager score:17.885219\n",
      "#8 subject:hockey word:the nhl score:17.907930\n",
      "#7 subject:christianity word:athos rutgers score:17.966964\n",
      "#6 subject:mideastpolitics word:the turkish score:18.258472\n",
      "#5 subject:mideastpolitics word:the armenian score:18.323786\n",
      "#4 subject:cryptology word:the clipper score:18.409485\n",
      "#3 subject:mideastpolitics word:the armenians score:18.622875\n",
      "#2 subject:cryptology word:clipper chip score:18.773452\n",
      "#1 subject:politics word:mr stephanopoulos score:18.928501\n",
      "#30 subject:mideastpolitics word:urartu sdpa org score:15.880700\n",
      "#29 subject:medicine word:geb cadre dsl score:15.931415\n",
      "#28 subject:medicine word:and geb cadre score:15.931415\n",
      "#27 subject:medicine word:intellect and geb score:15.931415\n",
      "#26 subject:mideastpolitics word:soviet armenia today score:15.965014\n",
      "#25 subject:christianity word:apr geneva rutgers score:15.996219\n",
      "#24 subject:hockey word:in the nhl score:15.997243\n",
      "#23 subject:medicine word:of the intellect score:16.011841\n",
      "#22 subject:medicine word:chastity of the score:16.011841\n",
      "#21 subject:medicine word:the chastity of score:16.011841\n",
      "#20 subject:medicine word:is the chastity score:16.011841\n",
      "#19 subject:medicine word:skepticism is the score:16.011841\n",
      "#18 subject:medicine word:jxp skepticism is score:16.011841\n",
      "#17 subject:atheism word:re political atheists score:16.023876\n",
      "#16 subject:mideastpolitics word:the turks and score:16.078572\n",
      "#15 subject:cryptology word:good any more score:16.102869\n",
      "#14 subject:cryptology word:re once tapped score:16.141700\n",
      "#13 subject:cryptology word:no good any score:16.141700\n",
      "#12 subject:cryptology word:code is no score:16.141700\n",
      "#11 subject:cryptology word:tapped your code score:16.141700\n",
      "#10 subject:cryptology word:once tapped your score:16.141700\n",
      "#9 subject:mideastpolitics word:of the turkish score:16.270366\n",
      "#8 subject:cryptology word:your code is score:16.289582\n",
      "#7 subject:christianity word:geneva rutgers edu score:16.560514\n",
      "#6 subject:mideastpolitics word:for policy research score:16.650573\n",
      "#5 subject:mideastpolitics word:center for policy score:16.706531\n",
      "#4 subject:christianity word:article apr athos score:17.405973\n",
      "#3 subject:christianity word:apr athos rutgers score:17.505410\n",
      "#2 subject:cryptology word:the clipper chip score:17.802295\n",
      "#1 subject:christianity word:athos rutgers edu score:17.961285\n",
      "atheism~~~~~~~~~~~~~~~~~~~~~\n",
      "\t5 word:islamic law score:14.316603\n",
      "\t4 word:ico tek score:15.117543\n",
      "\t3 word:vice ico score:15.117543\n",
      "\t2 word:political atheists score:16.032480\n",
      "\t1 word:re political score:16.073359\n",
      "\t5 word:darice yoyo cc score:13.189182\n",
      "\t4 word:ico tek com score:15.107561\n",
      "\t3 word:vice ico tek score:15.107561\n",
      "\t2 word:caltech edu keith score:15.509963\n",
      "\t1 word:re political atheists score:16.023876\n",
      "autos~~~~~~~~~~~~~~~~~~~~~\n",
      "\t5 word:new car score:12.905339\n",
      "\t4 word:dumbest automotive score:13.818175\n",
      "\t3 word:re warning score:13.952220\n",
      "\t2 word:warning please score:14.373516\n",
      "\t1 word:rec autos score:15.719419\n",
      "\t5 word:callison uokmax ecn score:12.446722\n",
      "\t4 word:re dumbest automotive score:13.491935\n",
      "\t3 word:dumbest automotive concepts score:13.709552\n",
      "\t2 word:warning please read score:14.368609\n",
      "\t1 word:re warning please score:14.368609\n",
      "baseball~~~~~~~~~~~~~~~~~~~~~\n",
      "\t5 word:jewish baseball score:14.301990\n",
      "\t4 word:red sox score:14.726762\n",
      "\t3 word:the yankees score:14.850439\n",
      "\t2 word:the phillies score:15.360770\n",
      "\t1 word:the braves score:16.845635\n",
      "\t5 word:players in article score:11.423639\n",
      "\t4 word:suck cubs suck score:12.457582\n",
      "\t3 word:re jewish baseball score:12.606145\n",
      "\t2 word:cubs suck cubs score:12.748970\n",
      "\t1 word:jewish baseball players score:14.113465\n",
      "christianity~~~~~~~~~~~~~~~~~~~~~\n",
      "\t5 word:holy spirit score:13.630599\n",
      "\t4 word:apr geneva score:16.006156\n",
      "\t3 word:geneva rutgers score:16.569351\n",
      "\t2 word:apr athos score:17.512183\n",
      "\t1 word:athos rutgers score:17.966964\n",
      "\t5 word:re the arrogance score:13.440173\n",
      "\t4 word:geneva rutgers edu score:16.560514\n",
      "\t3 word:article apr athos score:17.405973\n",
      "\t2 word:apr athos rutgers score:17.505410\n",
      "\t1 word:athos rutgers edu score:17.961285\n",
      "cryptology~~~~~~~~~~~~~~~~~~~~~\n",
      "\t5 word:the escrow score:16.244855\n",
      "\t4 word:key escrow score:17.786153\n",
      "\t3 word:the nsa score:17.797415\n",
      "\t2 word:the clipper score:18.409485\n",
      "\t1 word:clipper chip score:18.773452\n",
      "\t5 word:code is no score:16.141700\n",
      "\t4 word:tapped your code score:16.141700\n",
      "\t3 word:once tapped your score:16.141700\n",
      "\t2 word:your code is score:16.289582\n",
      "\t1 word:the clipper chip score:17.802295\n",
      "electronics~~~~~~~~~~~~~~~~~~~~~\n",
      "\t5 word:on hook score:10.794208\n",
      "\t4 word:grounding conductor score:12.304512\n",
      "\t3 word:ground wire score:12.459156\n",
      "\t2 word:the neutral score:13.556781\n",
      "\t1 word:cooling towers score:14.697029\n",
      "\t5 word:find out number score:9.791285\n",
      "\t4 word:cooling towers do score:10.317950\n",
      "\t3 word:do nuclear site score:10.792940\n",
      "\t2 word:what do nuclear score:10.792940\n",
      "\t1 word:radar detector detectors score:11.724036\n",
      "forsale~~~~~~~~~~~~~~~~~~~~~\n",
      "\t5 word:ghost rider score:12.678511\n",
      "\t4 word:picture sleeve score:13.216074\n",
      "\t3 word:copies each score:13.338353\n",
      "\t2 word:best offer score:15.528230\n",
      "\t1 word:for sale score:15.719031\n",
      "\t5 word:items for sale score:9.579550\n",
      "\t4 word:make an offer score:10.346577\n",
      "\t3 word:make me an score:11.243043\n",
      "\t2 word:me an offer score:11.296172\n",
      "\t1 word:or best offer score:12.463541\n",
      "graphics~~~~~~~~~~~~~~~~~~~~~\n",
      "\t5 word:op cols score:12.095917\n",
      "\t4 word:newsgroup split score:12.412397\n",
      "\t3 word:image processing score:12.543240\n",
      "\t2 word:computer graphics score:13.679196\n",
      "\t1 word:comp graphics score:15.517677\n",
      "\t5 word:philosophical significance of score:10.026938\n",
      "\t4 word:fast polygon routine score:10.283329\n",
      "\t3 word:re rumours about score:10.498447\n",
      "\t2 word:rumours about do score:10.758496\n",
      "\t1 word:aspects of graphics score:10.979068\n",
      "guns~~~~~~~~~~~~~~~~~~~~~\n",
      "\t5 word:semi auto score:14.888248\n",
      "\t4 word:my gun score:15.020820\n",
      "\t3 word:ifas ufl score:15.305944\n",
      "\t2 word:gnv ifas score:15.305944\n",
      "\t1 word:gun control score:16.324555\n",
      "\t5 word:re atf burns score:14.370344\n",
      "\t4 word:gun is like score:14.557669\n",
      "\t3 word:my gun is score:14.630052\n",
      "\t2 word:gnv ifas ufl score:15.311274\n",
      "\t1 word:ifas ufl edu score:15.493685\n",
      "hockey~~~~~~~~~~~~~~~~~~~~~\n",
      "\t5 word:pts pt score:15.862280\n",
      "\t4 word:the leafs score:16.929715\n",
      "\t3 word:the puck score:17.135718\n",
      "\t2 word:power play score:17.460506\n",
      "\t1 word:the nhl score:17.907930\n",
      "\t5 word:pt la vs score:13.662938\n",
      "\t4 word:in the playoffs score:14.408295\n",
      "\t3 word:power play scorer score:15.418645\n",
      "\t2 word:pts pt la score:15.473174\n",
      "\t1 word:in the nhl score:15.997243\n",
      "mac~~~~~~~~~~~~~~~~~~~~~\n",
      "\t5 word:scsi problems score:11.277980\n",
      "\t4 word:the duo score:12.355641\n",
      "\t3 word:mac ii score:12.518421\n",
      "\t2 word:lc iii score:13.318739\n",
      "\t1 word:the lc score:14.337833\n",
      "\t5 word:quadra scsi problems score:8.578018\n",
      "\t4 word:do they compare score:8.661707\n",
      "\t3 word:nada kth se score:8.810860\n",
      "\t2 word:on the mac score:9.246761\n",
      "\t1 word:comp sys mac score:9.837248\n",
      "medicine~~~~~~~~~~~~~~~~~~~~~\n",
      "\t5 word:and geb score:15.910009\n",
      "\t4 word:chastity of score:15.990752\n",
      "\t3 word:the chastity score:15.990752\n",
      "\t2 word:jxp skepticism score:15.990752\n",
      "\t1 word:gordon banks score:16.903320\n",
      "\t5 word:chastity of the score:16.011841\n",
      "\t4 word:the chastity of score:16.011841\n",
      "\t3 word:is the chastity score:16.011841\n",
      "\t2 word:skepticism is the score:16.011841\n",
      "\t1 word:jxp skepticism is score:16.011841\n",
      "mideastpolitics~~~~~~~~~~~~~~~~~~~~~\n",
      "\t5 word:soviet armenia score:17.047479\n",
      "\t4 word:the turks score:17.377391\n",
      "\t3 word:the turkish score:18.258472\n",
      "\t2 word:the armenian score:18.323786\n",
      "\t1 word:the armenians score:18.622875\n",
      "\t5 word:closed the roads score:15.837208\n",
      "\t4 word:the turks and score:16.078572\n",
      "\t3 word:of the turkish score:16.270366\n",
      "\t2 word:for policy research score:16.650573\n",
      "\t1 word:center for policy score:16.706531\n",
      "motorcycles~~~~~~~~~~~~~~~~~~~~~\n",
      "\t5 word:ryan cousineau score:12.762307\n",
      "\t4 word:rec motorcycles score:13.281932\n",
      "\t3 word:ed green score:14.031778\n",
      "\t2 word:my bike score:15.419486\n",
      "\t1 word:the bike score:17.619350\n",
      "\t5 word:compdyn questor org score:11.809721\n",
      "\t4 word:nj nec com score:12.300403\n",
      "\t3 word:east sun com score:12.324930\n",
      "\t2 word:egreen east sun score:12.468566\n",
      "\t1 word:hydro on ca score:13.043590\n",
      "mswindows~~~~~~~~~~~~~~~~~~~~~\n",
      "\t5 word:win ini score:12.134453\n",
      "\t4 word:linked on score:13.887620\n",
      "\t3 word:allocation unit score:13.987032\n",
      "\t2 word:cross linked score:14.354317\n",
      "\t1 word:swap file score:15.266509\n",
      "\t5 word:csie nctu edu score:9.588976\n",
      "\t4 word:on allocation unit score:13.867714\n",
      "\t3 word:linked on allocation score:13.867714\n",
      "\t2 word:cross linked on score:13.867714\n",
      "\t1 word:is cross linked score:13.867714\n",
      "pc~~~~~~~~~~~~~~~~~~~~~\n",
      "\t5 word:aspi dos score:13.840866\n",
      "\t4 word:isa bus score:14.623165\n",
      "\t3 word:controller card score:14.696885\n",
      "\t2 word:disk drives score:14.991107\n",
      "\t1 word:rom bios score:15.293362\n",
      "\t5 word:mb mb mb score:11.799812\n",
      "\t4 word:floppy disk drives score:12.458945\n",
      "\t3 word:re ide vs score:13.388899\n",
      "\t2 word:comp os os score:13.573938\n",
      "\t1 word:ide vs scsi score:13.720763\n",
      "politics~~~~~~~~~~~~~~~~~~~~~\n",
      "\t5 word:thor isc score:14.496909\n",
      "\t4 word:br com score:15.371327\n",
      "\t3 word:isc br score:16.489394\n",
      "\t2 word:ms myers score:17.056165\n",
      "\t1 word:mr stephanopoulos score:18.928501\n",
      "\t5 word:com clayton cramer score:13.688571\n",
      "\t4 word:senior administration official score:14.292670\n",
      "\t3 word:thor isc br score:14.495830\n",
      "\t2 word:steveh thor isc score:14.495830\n",
      "\t1 word:isc br com score:15.370920\n",
      "religion~~~~~~~~~~~~~~~~~~~~~\n",
      "\t5 word:mr decenso score:11.947303\n",
      "\t4 word:brian kendig score:12.097930\n",
      "\t3 word:royalroads ca score:12.276842\n",
      "\t2 word:the magi score:12.276842\n",
      "\t1 word:robert weiss score:13.588686\n",
      "\t5 word:sandvik kent apple score:11.050764\n",
      "\t4 word:newton apple com score:11.135608\n",
      "\t3 word:sandvik newton apple score:11.135608\n",
      "\t2 word:utarlg uta edu score:11.189668\n",
      "\t1 word:out of context score:11.342409\n",
      "space~~~~~~~~~~~~~~~~~~~~~\n",
      "\t5 word:kelvin jpl score:14.596454\n",
      "\t4 word:space shuttle score:15.130498\n",
      "\t3 word:sci space score:16.310144\n",
      "\t2 word:space station score:16.641208\n",
      "\t1 word:the moon score:16.726376\n",
      "\t5 word:digex com pat score:13.728189\n",
      "\t4 word:aurora alaska edu score:14.136173\n",
      "\t3 word:zoo toronto edu score:14.599382\n",
      "\t2 word:kelvin jpl nasa score:14.627165\n",
      "\t1 word:on the moon score:15.803821\n",
      "xwindows~~~~~~~~~~~~~~~~~~~~~\n",
      "\t5 word:lib xmu score:15.336830\n",
      "\t4 word:check io score:16.015778\n",
      "\t3 word:on export score:16.325635\n",
      "\t2 word:output oname score:16.863796\n",
      "\t1 word:window manager score:17.885219\n",
      "\t5 word:oname eof not score:14.974044\n",
      "\t4 word:io output oname score:14.974044\n",
      "\t3 word:check io output score:14.974044\n",
      "\t2 word:the window manager score:15.557563\n",
      "\t1 word:eof not ok score:15.754716\n"
     ]
    }
   ],
   "source": [
    "topLst2 = [{'subject':'','word':'','score':0}]*30\n",
    "topG2 = {g:[{'word':'','score':0}]*5 for g in trgroup.groups.keys()}\n",
    "topLst3 = [{'subject':'','word':'','score':0}]*30\n",
    "topG3 = {g:[{'word':'','score':0}]*5 for g in trgroup.groups.keys()}\n",
    "for word in vocab2:\n",
    "    cnt = False\n",
    "    for w in word.split(' '):\n",
    "        if(len(w)<2):\n",
    "            cnt=True\n",
    "    if(cnt):\n",
    "        continue\n",
    "    tot = 0\n",
    "    cnt = 0\n",
    "    for g in trgroup.groups.keys():\n",
    "        try:\n",
    "            tot += math.e**wtprob2[g][word]\n",
    "            cnt += 1\n",
    "        except KeyError as e:\n",
    "            print(e)\n",
    "            pass\n",
    "    if cnt ==0:\n",
    "        continue\n",
    "    avg = tot/cnt\n",
    "    for g in trgroup.groups.keys():\n",
    "        try:\n",
    "            v = (math.e**wtprob2[g][word])/avg\n",
    "        except KeyError:\n",
    "            print(e)\n",
    "            continue\n",
    "        for i in range(len(topG2[g])):\n",
    "            if v > topG2[g][i]['score']:\n",
    "                for j in range(len(topG2[g])-2,i,-1):\n",
    "                    topG2[g][j] = topG2[g][j-1]\n",
    "                topG2[g][i] = {'word':word,'score':v}\n",
    "                break\n",
    "        for i in range(len(topLst2)):\n",
    "            if v > topLst2[i]['score']:\n",
    "                for j in range(len(topLst2)-2,i,-1):\n",
    "                    topLst2[j] = topLst2[j-1]\n",
    "                topLst2[i] = {'subject':g,'word':word,'score':v}\n",
    "                break\n",
    "for word in vocab3:\n",
    "    cnt = False\n",
    "    for w in word.split(' '):\n",
    "        if(len(w)<2):\n",
    "            cnt=True\n",
    "    if(cnt):\n",
    "        continue\n",
    "    tot = 0\n",
    "    cnt = 0\n",
    "    for g in trgroup.groups.keys():\n",
    "        try:\n",
    "            tot += math.e**wtprob3[g][word]\n",
    "            cnt += 1\n",
    "        except KeyError as e:\n",
    "            print(e)\n",
    "            pass\n",
    "    if cnt ==0:\n",
    "        continue\n",
    "    avg = tot/cnt\n",
    "    for g in trgroup.groups.keys():\n",
    "        try:\n",
    "            v = (math.e**wtprob3[g][word])/avg\n",
    "        except KeyError:\n",
    "            print(e)\n",
    "            continue\n",
    "        for i in range(len(topG3[g])):\n",
    "            if v > topG3[g][i]['score']:\n",
    "                for j in range(len(topG3[g])-2,i,-1):\n",
    "                    topG3[g][j] = topG3[g][j-1]\n",
    "                topG3[g][i] = {'word':word,'score':v}\n",
    "                break\n",
    "        for i in range(len(topLst3)):\n",
    "            if v > topLst3[i]['score']:\n",
    "                for j in range(len(topLst3)-2,i,-1):\n",
    "                    topLst3[j] = topLst3[j-1]\n",
    "                topLst3[i] = {'subject':g,'word':word,'score':v}\n",
    "                break\n",
    "for i in range(len(topLst2)-1,-1,-1):\n",
    "    print(\"#%d subject:%s word:%s score:%f\"%(i+1,topLst2[i]['subject'],topLst2[i]['word'],topLst2[i]['score']))\n",
    "for i in range(len(topLst3)-1,-1,-1):\n",
    "    print(\"#%d subject:%s word:%s score:%f\"%(i+1,topLst3[i]['subject'],topLst3[i]['word'],topLst3[i]['score']))\n",
    "\n",
    "orderG = list(trgroup.groups.keys())\n",
    "orderG.sort()\n",
    "for g in orderG:\n",
    "    print(g+\"~~~~~~~~~~~~~~~~~~~~~\")\n",
    "    for i in range(len(topG2[g])-1,-1,-1):\n",
    "        print(\"\\t%d word:%s score:%f\"%(i+1,topG2[g][i]['word'],topG2[g][i]['score']))\n",
    "    for i in range(len(topG3[g])-1,-1,-1):\n",
    "        print(\"\\t%d word:%s score:%f\"%(i+1,topG3[g][i]['word'],topG3[g][i]['score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
